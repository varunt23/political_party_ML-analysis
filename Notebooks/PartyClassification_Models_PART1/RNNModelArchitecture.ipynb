{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import string, os \n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-31f16af7bdb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinaldf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CleanDemRepHouse.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "finaldf = pd.read_csv(\"CleanDemRepHouse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encod = LabelEncoder()\n",
    "finaldf['partyNum'] = encod.fit_transform(finaldf['party'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(finaldf,list(finaldf['partyNum'].values),test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127704, 4) (31927, 4)\n",
      "159631\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)\n",
    "print(len(finaldf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Pre-trained Glove Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127704, 50)\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size,lower=False,split=' ')\n",
    "trainFit = [str(x) for x in X_train['CleanText'].values]\n",
    "tokenizer.fit_on_texts(trainFit)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(trainFit)\n",
    "data = pad_sequences(sequences,maxlen=50)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.twitter.27B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a weight matrix for words in the training data\n",
    "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Sequential()\n",
    "mod.add(Embedding(vocabulary_size, 100, input_length=50, weights=[embedding_matrix], trainable=False))\n",
    "mod.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "mod.add(Dense(1, activation='sigmoid'))\n",
    "mod.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76622 samples, validate on 51082 samples\n",
      "Epoch 1/20\n",
      "76622/76622 [==============================] - 272s 4ms/step - loss: 0.6374 - accuracy: 0.6314 - val_loss: 0.5811 - val_accuracy: 0.6851\n",
      "Epoch 2/20\n",
      "76622/76622 [==============================] - 283s 4ms/step - loss: 0.5735 - accuracy: 0.6920 - val_loss: 0.5374 - val_accuracy: 0.7126\n",
      "Epoch 3/20\n",
      "76622/76622 [==============================] - 316s 4ms/step - loss: 0.5397 - accuracy: 0.7182 - val_loss: 0.5166 - val_accuracy: 0.7279\n",
      "Epoch 4/20\n",
      "76622/76622 [==============================] - 277s 4ms/step - loss: 0.5155 - accuracy: 0.7340 - val_loss: 0.5049 - val_accuracy: 0.7381\n",
      "Epoch 5/20\n",
      "76622/76622 [==============================] - 272s 4ms/step - loss: 0.4963 - accuracy: 0.7474 - val_loss: 0.5017 - val_accuracy: 0.7459\n",
      "Epoch 6/20\n",
      "76622/76622 [==============================] - 271s 4ms/step - loss: 0.4814 - accuracy: 0.7594 - val_loss: 0.4955 - val_accuracy: 0.7413\n",
      "Epoch 7/20\n",
      "76622/76622 [==============================] - 279s 4ms/step - loss: 0.4672 - accuracy: 0.7670 - val_loss: 0.4792 - val_accuracy: 0.7551\n",
      "Epoch 8/20\n",
      "76622/76622 [==============================] - 271s 4ms/step - loss: 0.4536 - accuracy: 0.7751 - val_loss: 0.4758 - val_accuracy: 0.7559\n",
      "Epoch 9/20\n",
      "76622/76622 [==============================] - 273s 4ms/step - loss: 0.4448 - accuracy: 0.7818 - val_loss: 0.4810 - val_accuracy: 0.7575\n",
      "Epoch 10/20\n",
      "76622/76622 [==============================] - 272s 4ms/step - loss: 0.4344 - accuracy: 0.7877 - val_loss: 0.4708 - val_accuracy: 0.7629\n",
      "Epoch 11/20\n",
      "76622/76622 [==============================] - 282s 4ms/step - loss: 0.4235 - accuracy: 0.7950 - val_loss: 0.4825 - val_accuracy: 0.7557\n",
      "Epoch 12/20\n",
      "76622/76622 [==============================] - 273s 4ms/step - loss: 0.4180 - accuracy: 0.7993 - val_loss: 0.4697 - val_accuracy: 0.7645\n",
      "Epoch 13/20\n",
      "76622/76622 [==============================] - 277s 4ms/step - loss: 0.4074 - accuracy: 0.8045 - val_loss: 0.4748 - val_accuracy: 0.7638\n",
      "Epoch 14/20\n",
      "76622/76622 [==============================] - 274s 4ms/step - loss: 0.3999 - accuracy: 0.8085 - val_loss: 0.4726 - val_accuracy: 0.7636\n",
      "Epoch 15/20\n",
      "76622/76622 [==============================] - 274s 4ms/step - loss: 0.3904 - accuracy: 0.8141 - val_loss: 0.4806 - val_accuracy: 0.7660\n",
      "Epoch 16/20\n",
      "76622/76622 [==============================] - 272s 4ms/step - loss: 0.3838 - accuracy: 0.8176 - val_loss: 0.4776 - val_accuracy: 0.7669\n",
      "Epoch 17/20\n",
      "76622/76622 [==============================] - 273s 4ms/step - loss: 0.3802 - accuracy: 0.8197 - val_loss: 0.4781 - val_accuracy: 0.7680\n",
      "Epoch 18/20\n",
      "76622/76622 [==============================] - 271s 4ms/step - loss: 0.3730 - accuracy: 0.8255 - val_loss: 0.4884 - val_accuracy: 0.7700\n",
      "Epoch 19/20\n",
      "76622/76622 [==============================] - 329s 4ms/step - loss: 0.3682 - accuracy: 0.8285 - val_loss: 0.4838 - val_accuracy: 0.7676\n",
      "Epoch 20/20\n",
      "76622/76622 [==============================] - 305s 4ms/step - loss: 0.3583 - accuracy: 0.8327 - val_loss: 0.4960 - val_accuracy: 0.7663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a4fce7f98>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(data, np.array(y_train), validation_split=0.4, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 50, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,080,501\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25005427]] Republican\n"
     ]
    }
   ],
   "source": [
    "new_tweet = ['']\n",
    "seq1 = tokenizer.texts_to_sequences(new_tweet)\n",
    "da1 = pad_sequences(seq1, maxlen=50)\n",
    "pred1 = mod.predict(da1)\n",
    "pred1\n",
    "# 0: Democrat, 1: Republican"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
