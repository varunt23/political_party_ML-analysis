{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "\n",
    "from wordcloud import WordCloud \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>CleanText</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1197243090605690881</td>\n",
       "      <td>cnn msnbc go inadvertently forgot mention andr...</td>\n",
       "      <td>2019-11-20 19:59:31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Restorer_Healer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1197243020535570433</td>\n",
       "      <td>andrew least speaking time every time efficien...</td>\n",
       "      <td>2019-11-20 19:59:14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Shigga11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1197243012604055552</td>\n",
       "      <td>unfortanly already started</td>\n",
       "      <td>2019-11-20 19:59:12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yanggang101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1197242987903717376</td>\n",
       "      <td>watch democratic debate andrew yang support an...</td>\n",
       "      <td>2019-11-20 19:59:06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TheAverageLefty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1197242902721773568</td>\n",
       "      <td>andrew yang promises give americans usd month ...</td>\n",
       "      <td>2019-11-20 19:58:46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reallyiscnn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TweetId                                          CleanText  \\\n",
       "0  1197243090605690881  cnn msnbc go inadvertently forgot mention andr...   \n",
       "1  1197243020535570433  andrew least speaking time every time efficien...   \n",
       "2  1197243012604055552                         unfortanly already started   \n",
       "3  1197242987903717376  watch democratic debate andrew yang support an...   \n",
       "4  1197242902721773568  andrew yang promises give americans usd month ...   \n",
       "\n",
       "             timestamp  likes  replies  retweets         username  \n",
       "0  2019-11-20 19:59:31      2        0         1  Restorer_Healer  \n",
       "1  2019-11-20 19:59:14      0        0         0         Shigga11  \n",
       "2  2019-11-20 19:59:12      0        1         0      yanggang101  \n",
       "3  2019-11-20 19:59:06      1        0         0  TheAverageLefty  \n",
       "4  2019-11-20 19:58:46      1        0         0      reallyiscnn  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AYBefore = pd.read_csv(\"ay2cleanB.csv\")\n",
    "AYBefore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    }
   ],
   "source": [
    "Sentiment= pd.read_csv(\"SAD.csv\", error_bad_lines = False)\n",
    "\n",
    "tvec = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "tfidf_transformer = tvec.fit(Sentiment.SentimentText)\n",
    "\n",
    "ay_x = tvec.transform(AYBefore['CleanText'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('classifier', lr)\n",
    "])\n",
    "\n",
    "\n",
    "x1 = tvec.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "y = Sentiment.Sentiment\n",
    "\n",
    "lr.fit =  pipeline2.fit(x1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ay_x = tvec.transform(AYBefore['CleanText'].values.astype('U'))\n",
    "#Andrew Yang Debate 2 Before\n",
    "AYprediction = lr.fit.predict(ay_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7716395112016293"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(AYprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>CleanText</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>username</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1197243090605690881</td>\n",
       "      <td>cnn msnbc go inadvertently forgot mention andr...</td>\n",
       "      <td>2019-11-20 19:59:31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Restorer_Healer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1197243020535570433</td>\n",
       "      <td>andrew least speaking time every time efficien...</td>\n",
       "      <td>2019-11-20 19:59:14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Shigga11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1197243012604055552</td>\n",
       "      <td>unfortanly already started</td>\n",
       "      <td>2019-11-20 19:59:12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yanggang101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1197242987903717376</td>\n",
       "      <td>watch democratic debate andrew yang support an...</td>\n",
       "      <td>2019-11-20 19:59:06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TheAverageLefty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1197242902721773568</td>\n",
       "      <td>andrew yang promises give americans usd month ...</td>\n",
       "      <td>2019-11-20 19:58:46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reallyiscnn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TweetId                                          CleanText  \\\n",
       "0  1197243090605690881  cnn msnbc go inadvertently forgot mention andr...   \n",
       "1  1197243020535570433  andrew least speaking time every time efficien...   \n",
       "2  1197243012604055552                         unfortanly already started   \n",
       "3  1197242987903717376  watch democratic debate andrew yang support an...   \n",
       "4  1197242902721773568  andrew yang promises give americans usd month ...   \n",
       "\n",
       "             timestamp  likes  replies  retweets         username  predictions  \n",
       "0  2019-11-20 19:59:31      2        0         1  Restorer_Healer            0  \n",
       "1  2019-11-20 19:59:14      0        0         0         Shigga11            1  \n",
       "2  2019-11-20 19:59:12      0        1         0      yanggang101            1  \n",
       "3  2019-11-20 19:59:06      1        0         0  TheAverageLefty            1  \n",
       "4  2019-11-20 19:58:46      1        0         0      reallyiscnn            1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AYBefore.head()\n",
    "df_AYBeforep = AYBefore.copy()\n",
    "df_AYBeforep['predictions'] = AYprediction\n",
    "df_AYBeforep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10810"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AYBefore) + len(AYAfter_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Debate 2 Andrew Yang Model predictions: Positives - 3031, Negatives - 897\n"
     ]
    }
   ],
   "source": [
    "pos = df_AYBeforep.predictions.value_counts()[0]\n",
    "neg = df_AYBeforep.predictions.value_counts()[1]\n",
    "\n",
    "print('Before Debate 2 Andrew Yang Model predictions: Positives - {}, Negatives - {}'.format(neg,pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Andrew Yang Debate 2 After\n",
    "AYAfter_2 = pd.read_csv(\"ay2cleanA.csv\")\n",
    "\n",
    "tvec9 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec9.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "ay2_xa = tvec9.transform(AYAfter_2['CleanText'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "AY2aprediction = lr.fit.predict(ay2_xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7393199651264167"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(AY2aprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Debate 2 Andrew Yang Model predictions: Positives - 5088, Negatives - 1794\n"
     ]
    }
   ],
   "source": [
    "df_AYAfterp = AYAfter_2.copy()\n",
    "df_AYAfterp['predictions'] = AY2aprediction \n",
    "df_AYAfterp.head()\n",
    "\n",
    "AYapos = df_AYAfterp.predictions.value_counts()[0]\n",
    "AYaneg = df_AYAfterp.predictions.value_counts()[1]\n",
    "\n",
    "print('After Debate 2 Andrew Yang Model predictions: Positives - {}, Negatives - {}'.format(neg,pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bernie Sanders Debate 2 Before\n",
    "BSBefore_2 = pd.read_csv(\"bs2cleanB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec1 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec1.fit_transform(Sentiment['SentimentText'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs2_xb = tvec1.transform(BSBefore_2['CleanText'].values.astype('U'))\n",
    "BS2bprediction = lr.fit.predict(bs2_xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3320637943346822"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(BS2bprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Debate 2 Bernie Model predictions: Positives - 1395, Negatives - 2806\n"
     ]
    }
   ],
   "source": [
    "df_BSBeforep = BSBefore_2.copy()\n",
    "df_BSBeforep['predictions'] = BS2bprediction\n",
    "df_BSBeforep.head()\n",
    "\n",
    "BSbpos = df_BSBeforep.predictions.value_counts()[0]\n",
    "BSbneg = df_BSBeforep.predictions.value_counts()[1]\n",
    "\n",
    "print('Before Debate 2 Bernie Model predictions: Positives - {}, Negatives - {}'.format(BSbneg,BSbpos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bernie Sanders Debate 2 After\n",
    "BSAfter_2 = pd.read_csv(\"bs2cleanA.csv\")\n",
    "\n",
    "tvec10 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec10.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "bs2_xa = tvec10.transform(BSAfter_2['CleanText'].values.astype('U'))\n",
    "BS2aprediction = lr.fit.predict(bs2_xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37265737626141276"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(BS2aprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Debate 2 Bernie Model predictions: Positives - 3102, Negatives - 5222\n"
     ]
    }
   ],
   "source": [
    "df_BSAfterp = BSAfter_2.copy()\n",
    "df_BSAfterp['predictions'] = BS2aprediction\n",
    "df_BSAfterp.head()\n",
    "\n",
    "BSapos = df_BSAfterp.predictions.value_counts()[0]\n",
    "BSaneg = df_BSAfterp.predictions.value_counts()[1]\n",
    "\n",
    "print('After Debate 2 Bernie Model predictions: Positives - {}, Negatives - {}'.format(BSaneg,BSapos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cory Booker Debate 2 Before\n",
    "CBBefore_2 = pd.read_csv(\"cb2cleanB.csv\")\n",
    "\n",
    "tvec2 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec2.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "cb2_xb = tvec2.transform(CBBefore_2['CleanText'].values.astype('U'))\n",
    "CB2bprediction = lr.fit.predict(cb2_xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8258785942492013"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(CB2bprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Debate 2 Cory Booker predictions: Positives - 1034, Negatives - 218\n"
     ]
    }
   ],
   "source": [
    "df_CBBeforep = CBBefore_2.copy()\n",
    "df_CBBeforep['predictions'] = CB2bprediction\n",
    "df_CBBeforep.head()\n",
    "\n",
    "CBbpos = df_CBBeforep.predictions.value_counts()[0]\n",
    "CBbneg = df_CBBeforep.predictions.value_counts()[1]\n",
    "\n",
    "print('Before Debate 2 Cory Booker predictions: Positives - {}, Negatives - {}'.format(CBbneg,CBbpos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cory Booker Debate 2 After\n",
    "CBAfter_2 = pd.read_csv(\"cb2cleanA.csv\")\n",
    "\n",
    "tvec11 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec11.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "cb2_xa = tvec11.transform(CBAfter_2['CleanText'].values.astype('U'))\n",
    "CB2aprediction = lr.fit.predict(cb2_xa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926470588235294"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(CB2aprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Debate 2 Cory Booker predictions: Positives - 5390, Negatives - 1410\n"
     ]
    }
   ],
   "source": [
    "df_CBAfterp = CBAfter_2.copy()\n",
    "df_CBAfterp['predictions'] = CB2aprediction\n",
    "df_CBAfterp.head()\n",
    "\n",
    "CBapos = df_CBAfterp.predictions.value_counts()[0]\n",
    "CBaneg = df_CBAfterp.predictions.value_counts()[1]\n",
    "\n",
    "print('After Debate 2 Cory Booker predictions: Positives - {}, Negatives - {}'.format(CBaneg,CBapos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elizabeth Warren Debate 2 Before\n",
    "EWBefore_2 = pd.read_csv(\"ew2cleanB.csv\")\n",
    "\n",
    "tvec3 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec3.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "ew2_xb = tvec3.transform(EWBefore_2['CleanText'].values.astype('U'))\n",
    "EW2bprediction = lr.fit.predict(ew2_xb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7604617604617605"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(EW2bprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Debate 2 Elizabeth Warren predictions: Positives - 4216, Negatives - 1328\n"
     ]
    }
   ],
   "source": [
    "df_EWBeforep = EWBefore_2.copy()\n",
    "df_EWBeforep['predictions'] = EW2bprediction\n",
    "df_EWBeforep.head()\n",
    "\n",
    "EWbpos = df_EWBeforep.predictions.value_counts()[0]\n",
    "EWbneg = df_EWBeforep.predictions.value_counts()[1]\n",
    "\n",
    "print('Before Debate 2 Elizabeth Warren predictions: Positives - {}, Negatives - {}'.format(EWbneg,EWbpos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elizabeth Warren Debate 2 After\n",
    "\n",
    "EWAfter_2 = pd.read_csv(\"ew2cleanA.csv\")\n",
    "\n",
    "tvec12 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec12.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "ew2_xa = tvec12.transform(EWAfter_2['CleanText'].values.astype('U'))\n",
    "EW2aprediction = lr.fit.predict(ew2_xa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7423120728929385"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(EW2aprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Debate 2 Elizabeth Warren predictions: Positives - 5214, Negatives - 1810\n"
     ]
    }
   ],
   "source": [
    "df_EWAfterp = EWAfter_2.copy()\n",
    "df_EWAfterp['predictions'] = EW2aprediction\n",
    "df_EWAfterp.head()\n",
    "\n",
    "EWapos = df_EWAfterp.predictions.value_counts()[0]\n",
    "EWaneg = df_EWAfterp.predictions.value_counts()[1]\n",
    "\n",
    "print('After Debate 2 Elizabeth Warren predictions: Positives - {}, Negatives - {}'.format(EWaneg,EWapos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joe Biden Debate 2 Before\n",
    "JBBefore_2 = pd.read_csv(\"jb2cleanB.csv\")\n",
    "\n",
    "tvec4 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec4.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "jb2_xb = tvec4.transform(JBBefore_2['CleanText'].values.astype('U'))\n",
    "JB2bprediction = lr.fit.predict(jb2_xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6740406320541761"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(JB2bprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Debate 2 Joe Biden predictions: Positives - 5972, Negatives - 2888\n"
     ]
    }
   ],
   "source": [
    "df_JBBeforep = JBBefore_2.copy()\n",
    "df_JBBeforep['predictions'] = JB2bprediction\n",
    "df_JBBeforep.head()\n",
    "\n",
    "JBbpos = df_JBBeforep.predictions.value_counts()[0]\n",
    "JBbneg = df_JBBeforep.predictions.value_counts()[1]\n",
    "\n",
    "print('Before Debate 2 Joe Biden predictions: Positives - {}, Negatives - {}'.format(JBbneg,JBbpos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joe Biden Debate 2 After\n",
    "\n",
    "JBAfter_2 = pd.read_csv(\"jb2cleanA.csv\")\n",
    "\n",
    "tvec13 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec13.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "jb2_xa = tvec13.transform(JBAfter_2['CleanText'].values.astype('U'))\n",
    "JB2aprediction = lr.fit.predict(jb2_xa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6899606299212598"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(JB2aprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Debate 2 Joe Biden predictions: Positives - 7711, Negatives - 3465\n"
     ]
    }
   ],
   "source": [
    "df_JBAfterp = JBAfter_2.copy()\n",
    "df_JBAfterp['predictions'] = JB2aprediction\n",
    "df_JBAfterp.head()\n",
    "\n",
    "JBapos = df_JBAfterp.predictions.value_counts()[0]\n",
    "JBaneg = df_JBAfterp.predictions.value_counts()[1]\n",
    "\n",
    "print('After Debate 2 Joe Biden predictions: Positives - {}, Negatives - {}'.format(JBaneg,JBapos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kamala Harris Debate 2 Before\n",
    "KHBefore_2 = pd.read_csv(\"kh2cleanB.csv\")\n",
    "\n",
    "tvec5 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec5.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "kh2_xb = tvec5.transform(KHBefore_2['CleanText'].values.astype('U'))\n",
    "KH2bprediction = lr.fit.predict(kh2_xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KH2bprediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7880952380952381"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(KH2bprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Debate 2 Kamala Harris predictions: Positives - 1986, Negatives - 534\n"
     ]
    }
   ],
   "source": [
    "df_KHBeforep = KHBefore_2.copy()\n",
    "df_KHBeforep['predictions'] = KH2bprediction\n",
    "df_KHBeforep.head()\n",
    "\n",
    "KHbpos = df_KHBeforep.predictions.value_counts()[0]\n",
    "KHbneg = df_KHBeforep.predictions.value_counts()[1]\n",
    "\n",
    "print('Before Debate 2 Kamala Harris predictions: Positives - {}, Negatives - {}'.format(KHbneg,KHbpos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kamala Harris Debate 2 After\n",
    "\n",
    "KHAfter_2 = pd.read_csv(\"kh2cleanA.csv\")\n",
    "\n",
    "tvec14 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec14.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "kh2_xa = tvec14.transform(KHAfter_2['CleanText'].values.astype('U'))\n",
    "KH2aprediction = lr.fit.predict(kh2_xa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7612770943175161"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(KH2aprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Debate 2 Kamala Harris predictions: Positives - 5198, Negatives - 1630\n"
     ]
    }
   ],
   "source": [
    "df_KHAfterp = KHAfter_2.copy()\n",
    "df_KHAfterp['predictions'] = KH2aprediction\n",
    "df_KHAfterp.head()\n",
    "\n",
    "KHapos = df_KHAfterp.predictions.value_counts()[0]\n",
    "KHaneg = df_KHAfterp.predictions.value_counts()[1]\n",
    "\n",
    "print('After Debate 2 Kamala Harris predictions: Positives - {}, Negatives - {}'.format(KHaneg,KHapos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pete Buttigieg Debate 2 Before\n",
    "PBBefore_2 = pd.read_csv(\"pb2cleanB.csv\")\n",
    "\n",
    "tvec6 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec6.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "pb2_xb = tvec6.transform(PBBefore_2['CleanText'].values.astype('U'))\n",
    "PB2bprediction = lr.fit.predict(pb2_xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8048985069619191"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(PB2bprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Debate 2 Pete Buttigeig predictions: Positives - 4798, Negatives - 1163\n"
     ]
    }
   ],
   "source": [
    "df_PBBeforep = PBBefore_2.copy()\n",
    "df_PBBeforep['predictions'] = PB2bprediction\n",
    "df_PBBeforep.head()\n",
    "\n",
    "PBbpos = df_PBBeforep.predictions.value_counts()[0]\n",
    "PBbneg = df_PBBeforep.predictions.value_counts()[1]\n",
    "\n",
    "print('Before Debate 2 Pete Buttigeig predictions: Positives - {}, Negatives - {}'.format(PBbneg,PBbpos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pete Buttigieg Debate 2 After\n",
    "\n",
    "PBAfter_2 = pd.read_csv(\"pb2cleanA.csv\")\n",
    "\n",
    "tvec15 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec15.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "pb2_xa = tvec15.transform(PBAfter_2['CleanText'].values.astype('U'))\n",
    "PB2aprediction = lr.fit.predict(pb2_xa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7771566701918718"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(PB2aprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Debate 2 Pete Buttigieg predictions: Positives - 5144, Negatives - 1475\n"
     ]
    }
   ],
   "source": [
    "df_PBAfterp = PBAfter_2.copy()\n",
    "df_PBAfterp['predictions'] = PB2aprediction\n",
    "df_PBAfterp.head()\n",
    "\n",
    "PBapos = df_PBAfterp.predictions.value_counts()[0]\n",
    "PBaneg = df_PBAfterp.predictions.value_counts()[1]\n",
    "\n",
    "print('After Debate 2 Pete Buttigieg predictions: Positives - {}, Negatives - {}'.format(PBaneg,PBapos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tulsi Gabbard Debate 2 Before\n",
    "TGBefore_2 = pd.read_csv(\"tg2cleanB.csv\")\n",
    "\n",
    "tvec7 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec7.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "tg2_xb = tvec7.transform(TGBefore_2['CleanText'].values.astype('U'))\n",
    "TG2bprediction = lr.fit.predict(tg2_xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7418960244648318"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(TG2bprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Debate 2 Tulsi Gabbard predictions: Positives - 1213, Negatives - 422\n"
     ]
    }
   ],
   "source": [
    "df_TGBeforep = TGBefore_2.copy()\n",
    "df_TGBeforep['predictions'] = TG2bprediction\n",
    "df_TGBeforep.head()\n",
    "\n",
    "TGbpos = df_TGBeforep.predictions.value_counts()[0]\n",
    "TGbneg = df_TGBeforep.predictions.value_counts()[1]\n",
    "\n",
    "print('Before Debate 2 Tulsi Gabbard predictions: Positives - {}, Negatives - {}'.format(TGbneg,TGbpos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tulsi Gabbard Debate 2 After\n",
    "\n",
    "TGAfter_2 = pd.read_csv(\"tg2cleanA.csv\")\n",
    "\n",
    "tvec16 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec16.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "tg2_xa = tvec16.transform(TGAfter_2['CleanText'].values.astype('U'))\n",
    "TG2aprediction = lr.fit.predict(tg2_xa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7078736587577452"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(TG2aprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Debate 2 Tulsi Gabbard predictions: Positives - 4684, Negatives - 1933\n"
     ]
    }
   ],
   "source": [
    "df_TGAfterp = TGAfter_2.copy()\n",
    "df_TGAfterp['predictions'] = TG2aprediction\n",
    "df_TGAfterp.head()\n",
    "\n",
    "TGapos = df_TGAfterp.predictions.value_counts()[0]\n",
    "TGaneg = df_TGAfterp.predictions.value_counts()[1]\n",
    "\n",
    "print('After Debate 2 Tulsi Gabbard predictions: Positives - {}, Negatives - {}'.format(TGaneg,TGapos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tom Stayer Debate 2 Before\n",
    "TSBefore_2 = pd.read_csv(\"ts2cleanB.csv\")\n",
    "\n",
    "tvec8 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec8.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "ts2_xb = tvec8.transform(TSBefore_2['CleanText'].values.astype('U'))\n",
    "TS2bprediction = lr.fit.predict(ts2_xb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7374301675977654"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(TS2bprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Debate 2 Tom Stayer predictions: Positives - 396, Negatives - 141\n"
     ]
    }
   ],
   "source": [
    "df_TSBeforep = TSBefore_2.copy()\n",
    "df_TSBeforep['predictions'] = TS2bprediction\n",
    "df_TSBeforep.head()\n",
    "\n",
    "TSbpos = df_TSBeforep.predictions.value_counts()[0]\n",
    "TSbneg = df_TSBeforep.predictions.value_counts()[1]\n",
    "\n",
    "print('Before Debate 2 Tom Stayer predictions: Positives - {}, Negatives - {}'.format(TSbneg,TSbpos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tom Stayer Debate 2 After \n",
    "\n",
    "TSAfter_2 = pd.read_csv(\"ts2cleanA.csv\")\n",
    "\n",
    "tvec17 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec17.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "ts2_xa = tvec17.transform(TSAfter_2['CleanText'].values.astype('U'))\n",
    "TS2aprediction = lr.fit.predict(ts2_xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.663417803768681"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(TS2aprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Debate 2 Tom Stayer predictions: Positives - 4084, Negatives - 2072\n"
     ]
    }
   ],
   "source": [
    "df_TSAfterp = TSAfter_2.copy()\n",
    "df_TSAfterp['predictions'] = TS2aprediction\n",
    "df_TSAfterp.head()\n",
    "\n",
    "TSapos = df_TSAfterp.predictions.value_counts()[0]\n",
    "TSaneg = df_TSAfterp.predictions.value_counts()[1]\n",
    "\n",
    "print('After Debate 2 Tom Stayer predictions: Positives - {}, Negatives - {}'.format(TSaneg,TSapos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amy Debate 2 Before\n",
    "\n",
    "AKBefore_2 = pd.read_csv(\"ak2cleanB.csv\")\n",
    "\n",
    "tvec18 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec18.fit_transform(Sentiment.SentimentText)\n",
    "\n",
    "ak2_xb = tvec18.transform(AKBefore_2['CleanText'].values.astype('U'))\n",
    "AK2bprediction = lr.fit.predict(ak2_xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7645348837209303"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(AK2bprediction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Debate 2 Amy Klobuchar predictions: Positives - 1052, Negatives - 324\n"
     ]
    }
   ],
   "source": [
    "df_AKBeforep = AKBefore_2.copy()\n",
    "df_AKBeforep['predictions'] = AK2bprediction\n",
    "df_AKBeforep.head()\n",
    "\n",
    "AKbpos = df_AKBeforep.predictions.value_counts()[0]\n",
    "AKbneg = df_AKBeforep.predictions.value_counts()[1]\n",
    "\n",
    "print('Before Debate 2 Amy Klobuchar predictions: Positives - {}, Negatives - {}'.format(AKbneg,AKbpos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amy Debate 2 After \n",
    "\n",
    "AKAfter_2 = pd.read_csv(\"ak2cleanA.csv\")\n",
    "\n",
    "tvec19 = TfidfVectorizer(stop_words = None, max_features = 100000, ngram_range = (1,3))\n",
    "x2 = tvec19.fit_transform(Sentiment['SentimentText'].values.astype('U'))\n",
    "\n",
    "ak2_xa = tvec19.transform(AKAfter_2['CleanText'].values.astype('U'))\n",
    "AK2aprediction = lr.fit.predict(ak2_xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7556171129578332"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(AK2aprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Debate 2 Amy Klobuchar predictions: Positives - 2455, Negatives - 794\n"
     ]
    }
   ],
   "source": [
    "df_AKAfterp = AKAfter_2.copy()\n",
    "df_AKAfterp['predictions'] = AK2aprediction\n",
    "df_AKAfterp.head()\n",
    "\n",
    "AKapos = df_AKAfterp.predictions.value_counts()[0]\n",
    "AKaneg = df_AKAfterp.predictions.value_counts()[1]\n",
    "\n",
    "print('After Debate 2 Amy Klobuchar predictions: Positives - {}, Negatives - {}'.format(AKaneg,AKapos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6693"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TSBefore_2) + len(TSAfter_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "396+141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
